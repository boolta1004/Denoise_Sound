{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574d6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "최 = []\n",
    "유 = []\n",
    "경 = []\n",
    "최_label = []\n",
    "유_label = []\n",
    "경_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ecc5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wave_generator(path): \n",
    "       \n",
    "    batch_waves = []\n",
    "    labels = []\n",
    "    # input_width=CHUNK*6 # wow, big!!\n",
    "    folders = os.listdir(path)\n",
    "    # folders = path\n",
    "    #while True:\n",
    "       # print(\"loaded batch of %d files\" % len(files))\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(path):continue               #폴더가 아니면 continue                   \n",
    "        files = os.listdir(path+\"/\"+folder)        \n",
    "        print(\"Foldername :\",folder,\", - file count : \",len(files))         #폴더 이름과 그 폴더에 속하는 파일 갯수 출력\n",
    "        if(folder == \"0\"):\n",
    "            for wav in files:\n",
    "                if not wav.endswith(\".wav\"):continue\n",
    "                else:\n",
    "                    global 최,최_label            #전역변수를 사용하겠다.\n",
    "                    print(\"Filename :\",wav)          #.wav 파일이 아니면 continue\n",
    "                    y, sr = librosa.load(path+\"/\"+folder+\"/\"+wav)\n",
    "                    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=45, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "\n",
    "\n",
    "                    if(len(최)==0):\n",
    "                        최 = mfcc\n",
    "                        최_label = np.full(len(mfcc), int(folder))\n",
    "                    else:\n",
    "                        최 = np.concatenate((최, mfcc), axis = 0)\n",
    "                        최_label = np.concatenate((최_label, np.full(len(mfcc),  int(folder))), axis = 0)\n",
    "                        #print(\"mfcc :\",mfcc.shape)\n",
    "        if(folder == \"1\"):\n",
    "            for wav in files:\n",
    "                if not wav.endswith(\".wav\"):continue\n",
    "                else:\n",
    "                    global 유,유_label\n",
    "                    print(\"Filename :\",wav)\n",
    "                    y, sr = librosa.load(path+\"/\"+folder+\"/\"+wav)\n",
    "                    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=45, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "\n",
    "\n",
    "                    if(len(유)==0):\n",
    "                        유 = mfcc\n",
    "                        유_label = np.full(len(mfcc), int(folder))\n",
    "                    else:\n",
    "                        유 = np.concatenate((유, mfcc), axis = 0)\n",
    "                        유_label = np.concatenate((유_label, np.full(len(mfcc),  int(folder))), axis = 0)\n",
    "                        #print(\"mfcc :\",mfcc.shape)\n",
    "        if(folder == \"2\"):\n",
    "            for wav in files:\n",
    "                if not wav.endswith(\".wav\"):continue\n",
    "                else:\n",
    "                    global 경, 경_label#전역변수를 사용하겠다.\n",
    "                    print(\"Filename :\",wav)#.wav 파일이 아니면 continue\n",
    "                    y, sr = librosa.load(path+\"/\"+folder+\"/\"+wav)\n",
    "                    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=45, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "\n",
    "\n",
    "                    if(len(경)==0):\n",
    "                        경 = mfcc\n",
    "                        경_label = np.full(len(mfcc), int(folder))\n",
    "                    else:\n",
    "                        경 = np.concatenate((경, mfcc), axis = 0)\n",
    "                        경_label = np.concatenate((경_label, np.full(len(mfcc),  int(folder))), axis = 0)\n",
    "                        #print(\"mfcc :\",mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e8935c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foldername : .ipynb_checkpoints , - file count :  0\n",
      "Foldername : 0 , - file count :  20\n",
      "Filename : 1.wav\n",
      "Filename : 10.wav\n",
      "Filename : 11.wav\n",
      "Filename : 12.wav\n",
      "Filename : 13.wav\n",
      "Filename : 14.wav\n",
      "Filename : 15.wav\n",
      "Filename : 16.wav\n",
      "Filename : 17.wav\n",
      "Filename : 18.wav\n",
      "Filename : 19.wav\n",
      "Filename : 2.wav\n",
      "Filename : 20.wav\n",
      "Filename : 3.wav\n",
      "Filename : 4.wav\n",
      "Filename : 5.wav\n",
      "Filename : 6.wav\n",
      "Filename : 7.wav\n",
      "Filename : 8.wav\n",
      "Filename : 9.wav\n",
      "Foldername : 1 , - file count :  20\n",
      "Filename : Ryu1.wav\n",
      "Filename : Ryu10.wav\n",
      "Filename : Ryu11.wav\n",
      "Filename : Ryu12.wav\n",
      "Filename : Ryu13.wav\n",
      "Filename : Ryu14.wav\n",
      "Filename : Ryu15.wav\n",
      "Filename : Ryu16.wav\n",
      "Filename : Ryu17.wav\n",
      "Filename : Ryu18.wav\n",
      "Filename : Ryu19.wav\n",
      "Filename : Ryu2.wav\n",
      "Filename : Ryu20.wav\n",
      "Filename : Ryu3.wav\n",
      "Filename : Ryu4.wav\n",
      "Filename : Ryu5.wav\n",
      "Filename : Ryu6.wav\n",
      "Filename : Ryu7.wav\n",
      "Filename : Ryu8.wav\n",
      "Filename : Ryu9.wav\n",
      "Foldername : 2 , - file count :  20\n",
      "Filename : 경재원1.wav\n",
      "Filename : 경재원10.wav\n",
      "Filename : 경재원11.wav\n",
      "Filename : 경재원12.wav\n",
      "Filename : 경재원13.wav\n",
      "Filename : 경재원14.wav\n",
      "Filename : 경재원15.wav\n",
      "Filename : 경재원16.wav\n",
      "Filename : 경재원17.wav\n",
      "Filename : 경재원18.wav\n",
      "Filename : 경재원19.wav\n",
      "Filename : 경재원2.wav\n",
      "Filename : 경재원20.wav\n",
      "Filename : 경재원3.wav\n",
      "Filename : 경재원4.wav\n",
      "Filename : 경재원5.wav\n",
      "Filename : 경재원6.wav\n",
      "Filename : 경재원7.wav\n",
      "Filename : 경재원8.wav\n",
      "Filename : 경재원9.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_wave_generator(\"../sound_data\")    #일단 RYU 음성 읽어오기\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed5ffbf1",
   "metadata": {},
   "source": [
    "# mfcc 역변환하는 방법\n",
    "mfcc_temp = np.array(mfcc_data).T\n",
    "mfcc_temp.shape\n",
    "sr = 22050\n",
    "#mfcc 추출\n",
    "# mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=60)\n",
    "\n",
    "#mfcc에서 역변환\n",
    "re_wav = librosa.feature.inverse.mfcc_to_audio(mfcc_temp[:,:500])\n",
    "                                              \n",
    "                                               #wav 파형 출력\n",
    "librosa.display.waveplot(re_wav, sr=sr, color='r')\n",
    "#파일 저장\n",
    "sf.write('./output_test.wav', re_wav, sr, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80950027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 상속\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self, x, y, transform):\n",
    "    self.x_data = x\n",
    "    self.y_data = y\n",
    "    self.transform = transform\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    x = torch.FloatTensor(self.x_data[idx])\n",
    "    y = torch.FloatTensor(self.y_data[idx])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebdecaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 45\n",
    "num_epochs = 200\n",
    "batch_size = 100\n",
    "sample_dir = 'samples'\n",
    "\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de88f194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49326, 45), (49326,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.concatenate([최,유,경])\n",
    "y = np.concatenate([최_label,유_label,경_label])\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384ee901",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./연습폴더/최유경_data', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d930544",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./연습폴더/최유경_label', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1ab0e1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-402.04608"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T[0][1244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "432346c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[45515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b3df849",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5],   # 1 for greyscale channels\n",
    "                                     std=[0.5])])\n",
    "\n",
    "dataset = CustomDataset(x.T, y, transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b75820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([45, 49326])\n",
      "torch.Size([45, 0])\n"
     ]
    }
   ],
   "source": [
    "for i, (wav, _) in enumerate(dataloader):\n",
    "#     wav = wav.reshape(batch_size, -1).to(device)\n",
    "    print(i)\n",
    "    print(wav.shape)\n",
    "    print(_.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "766351e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n",
      "1\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n",
      "2\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for i, (wav, _) in enumerate(data_loader):\n",
    "    wav = wav.reshape(batch_size, -1).to(device)\n",
    "    print(i)\n",
    "    print(wav.shape)\n",
    "    print(_.shape)\n",
    "    if i == 2:\n",
    "        break\n",
    "        \n",
    "        \n",
    "# 시발 어떻게 하는거야?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "abfa6828",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[100, -1]' is invalid for input of size 2219670",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-85dbed7da81c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# Create the labels which are later used as input for the BCE loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[100, -1]' is invalid for input of size 2219670"
     ]
    }
   ],
   "source": [
    "# Discriminator\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, 1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "# Generator \n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, image_size),\n",
    "    nn.Tanh())\n",
    "\n",
    "# Device setting\n",
    "D = D.to(device)\n",
    "G = G.to(device)\n",
    "\n",
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()\n",
    "\n",
    "# Start training\n",
    "total_step = len(data_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(dataloader):\n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "        \n",
    "        # Create the labels which are later used as input for the BCE loss\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                      Train the discriminator                       #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # Second term of the loss is always zero since real_labels == 1\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # Compute BCELoss using fake images\n",
    "        # First term of the loss is always zero since fake_labels == 0\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # ================================================================== #\n",
    "        #                        Train the generator                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute loss with fake images\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
    "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "    \n",
    "    # Save real images\n",
    "    if (epoch+1) == 1:\n",
    "        images = images.reshape(images.size(0), 1, 28, 28)\n",
    "        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
    "    \n",
    "    # Save sampled images\n",
    "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
    "\n",
    "# Save the model checkpoints \n",
    "torch.save(G.state_dict(), 'G.ckpt')\n",
    "torch.save(D.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22f29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
